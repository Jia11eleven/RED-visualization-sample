{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3311bb-9247-4a7a-ba47-a6323aa60308",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from matplotlib_venn import venn3\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e4e3ed-1874-45e2-b83c-c9468727b437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Coding\\\\Caleb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"D:/Coding/Caleb\"\n",
    "os.chdir(path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2117686-9a93-4d94-bc99-74d40cd0a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.read_json('./data/time.json')\n",
    "df_general = pd.read_json('./data/general.json')\n",
    "df_popularity = pd.read_json('./data/popularity.json')\n",
    "df_combined = pd.concat([df_time, df_general, df_popularity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85772e88-bef7-4018-bc1b-fa6fb0b99f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_combined.drop_duplicates('note_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb44462-9066-40d8-ab03-04d5a92296cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], unit=\"ms\", origin=\"unix\", utc=True).dt.tz_localize(None)\n",
    "df[\"last_modify_ts\"] = pd.to_datetime(df[\"last_modify_ts\"], unit=\"ms\", origin=\"unix\", utc=True).dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e76160d7-c731-4844-915f-ec8af81c9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"video_url\",\"avatar\",\"image_list\",\"last_modify_ts\",\"xsec_token\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b94be4e2-d984-4e5d-9114-c46b4f855343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"creation_date\"] = df[\"time\"].dt.date\n",
    "df[\"creation_time\"] = df[\"time\"].dt.time\n",
    "df[\"creation_year_month\"] = df[\"time\"].dt.to_period('M')\n",
    "df[\"time_diff\"] = (df[\"time\"] - df[\"last_update_time\"]).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35559c1e-a50b-4380-b565-eee895e7bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"content_edit\"] = df[\"time_diff\"] > pd.Timedelta(minutes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164ee829-ce58-453b-a20f-a5ecb050b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tags\"] = df[\"tag_list\"].str.split(\",\\s*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "918030ea-fd94-41ee-ac3d-c7f170ec6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_numeric(value):\n",
    "    if isinstance(value, str):\n",
    "        match = re.match(r\"([0-9\\.]+)万\", value) \n",
    "        if match:\n",
    "            return str(int(float(match.group(1)) * 10000))\n",
    "        match = re.match(r\"([0-9\\.]+)千.*\", value) \n",
    "        if match:\n",
    "            return str(int(float(match.group(1)) * 1000)) \n",
    "        match = re.match(r\"([0-9]+)\\+\", value)\n",
    "        if match:\n",
    "            return str(int(match.group(1))) \n",
    "    return value\n",
    "\n",
    "# Apply the function to the 'xxx_count' column\n",
    "df['liked_count_parsed'] = df['liked_count'].apply(convert_to_numeric)\n",
    "df['collected_count_parsed'] = df['collected_count'].apply(convert_to_numeric)\n",
    "df['comment_count_parsed'] = df['comment_count'].apply(convert_to_numeric)\n",
    "df['share_count_parsed'] = df['share_count'].apply(convert_to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e9350ab-617a-4d79-b40a-2c6c9ec49da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct count columns\n",
    "df[['liked_count_parsed', 'collected_count_parsed',\n",
    "    'comment_count_parsed', 'share_count_parsed']] = df[['liked_count_parsed', 'collected_count_parsed',\n",
    "                                                         'comment_count_parsed', 'share_count_parsed']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7ec93d-5e5a-47e5-b5ed-5b6ec67bc437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['note_id', 'type', 'title', 'desc', 'time', 'last_update_time',\n",
       "       'user_id', 'nickname', 'liked_count', 'collected_count',\n",
       "       'comment_count', 'share_count', 'ip_location', 'tag_list', 'note_url',\n",
       "       'source_keyword', 'creation_date', 'creation_time',\n",
       "       'creation_year_month', 'time_diff', 'content_edit', 'tags',\n",
       "       'liked_count_parsed', 'collected_count_parsed', 'comment_count_parsed',\n",
       "       'share_count_parsed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701d0f3f-8bba-497e-a180-af9ae9389787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['liked_count', 'collected_count','comment_count', 'share_count'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99d9ab3b-4fbc-4b75-8435-7ce0dbb0071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[df.creation_year_month>'2025-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78817dfa-96ad-4ca7-8323-cceeb4c5d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'tags'] = df['tags'].apply(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf70f86c-906a-49e2-bc5f-3aa099ac4b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_groups = ['上海', '中国台湾', '中国澳门', '中国香港', '云南', '内蒙古', '加拿大', '北京','吉林', '四川', '天津', '安徽', '山东', '山西',\n",
    "             '广东', '广西', '意大利', '挪威', '新加坡','新疆', '日本', '江苏', '江西', '河北', '河南', '浙江', '海南', '湖北', '湖南',\n",
    "             '澳大利亚','甘肃', '福建', '美国', '英国', '贵州', '辽宁', '重庆', '陕西', '马来西亚', '黑龙江']\n",
    "\n",
    "df.loc[:, 'ip_location_grouped'] = df['ip_location'].apply(\n",
    "    lambda x: x if (x in ip_groups)\n",
    "    else \"Others\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d60ee94-ebd7-4953-9952-17721b846869",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_tags = ['沈星回','黎深','秦彻','祁煜']\n",
    "caleb_tags = ['夏以昼','恋与深空夏以昼','夏以昼回航','夏以昼x你','Caleb','爱在夏以昼','夏以昼同人','夏以昼回来','夏以昼日常']\n",
    "\n",
    "def classify_post(tags):\n",
    "    tags_set = set(tags)  # Convert list to set for fast lookup\n",
    "    if any(tag in tags_set for tag in caleb_tags):  # Rule 1: Caleb-related tags exist\n",
    "        if any(tag in tags_set for tag in exclude_tags):  # Rule 2: Exclude tags exist\n",
    "            return \"General Post\"\n",
    "        return \"Caleb Post\"\n",
    "    return \"General Post\"  # Default if no Caleb tags found\n",
    "\n",
    "df = df.assign(post_type=df['tags'].apply(classify_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a33fef8-456b-4b7c-a647-15ccd48cb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment_like_ratio'] = df.apply(\n",
    "    lambda row: row['comment_count_parsed'] / row['liked_count_parsed'] if row['liked_count_parsed'] > 0 else None, \n",
    "    axis=1\n",
    ")\n",
    "df_comments = df.dropna(subset=['comment_like_ratio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "613c7f01-6e87-4d91-ab81-5d07bf1b99ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(668, 25)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94e375d0-df41-447e-9261-4e416723534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>time</th>\n",
       "      <th>last_update_time</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nickname</th>\n",
       "      <th>ip_location</th>\n",
       "      <th>tag_list</th>\n",
       "      <th>...</th>\n",
       "      <th>time_diff</th>\n",
       "      <th>content_edit</th>\n",
       "      <th>tags</th>\n",
       "      <th>liked_count_parsed</th>\n",
       "      <th>collected_count_parsed</th>\n",
       "      <th>comment_count_parsed</th>\n",
       "      <th>share_count_parsed</th>\n",
       "      <th>ip_location_grouped</th>\n",
       "      <th>post_type</th>\n",
       "      <th>comment_like_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67c27a66000000000603d771</td>\n",
       "      <td>video</td>\n",
       "      <td>是谁的卡册来了</td>\n",
       "      <td>给大家准备的福福来啦\\n﻿#恋与深空[话题]#﻿ ﻿#拆卡[话题]#﻿ ﻿#二创[话题]#﻿...</td>\n",
       "      <td>2025-03-01 03:09:26</td>\n",
       "      <td>2025-03-01 03:09:27</td>\n",
       "      <td>666c6100000000000d026ec1</td>\n",
       "      <td>芝士塔爱拆卡</td>\n",
       "      <td>河北</td>\n",
       "      <td>恋与深空,拆卡,二创,沈星回,黎深,祁煜,秦彻,夏以昼,卡册</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>False</td>\n",
       "      <td>[恋与深空, 拆卡, 二创, 沈星回, 黎深, 祁煜, 秦彻, 夏以昼, 卡册]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>河北</td>\n",
       "      <td>General Post</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67c27a45000000002903da90</td>\n",
       "      <td>normal</td>\n",
       "      <td>哇塞，这就是你们温良哥推吗，说不过就开始举报了\\n#沈星回[话题]#  #夏以昼的女人是小偷...</td>\n",
       "      <td>哇塞，这就是你们温良哥推吗，说不过就开始举报了\\n#沈星回[话题]#  #夏以昼的女人是小偷...</td>\n",
       "      <td>2025-03-01 03:08:53</td>\n",
       "      <td>2025-03-01 03:08:53</td>\n",
       "      <td>60587996000000000101f0c5</td>\n",
       "      <td>沈珏</td>\n",
       "      <td>江苏</td>\n",
       "      <td>沈星回,夏以昼的女人是小偷,夏以昼的女人不读书,夏以昼的女人吃拼好饭中毒</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "      <td>False</td>\n",
       "      <td>[沈星回, 夏以昼的女人是小偷, 夏以昼的女人不读书, 夏以昼的女人吃拼好饭中毒]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>江苏</td>\n",
       "      <td>General Post</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67c27a2c0000000006028cc9</td>\n",
       "      <td>normal</td>\n",
       "      <td>就这么和夏以昼叱咤风云😼</td>\n",
       "      <td>过了两年，妹也偷偷去参加了比武大会，各家很快就认出来妹用的招式是夏以昼的影子\\n妹和哥一样默...</td>\n",
       "      <td>2025-03-01 03:08:28</td>\n",
       "      <td>2025-03-01 03:08:29</td>\n",
       "      <td>632510f2000000002303c666</td>\n",
       "      <td>下一周有下雨天</td>\n",
       "      <td>广西</td>\n",
       "      <td>恋与深空夏以昼,夏以昼,恋与深空</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>False</td>\n",
       "      <td>[恋与深空夏以昼, 夏以昼, 恋与深空]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>广西</td>\n",
       "      <td>Caleb Post</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67c2783b000000000602822a</td>\n",
       "      <td>normal</td>\n",
       "      <td>模仿夏以昼签名被抓</td>\n",
       "      <td>#恋与深空夏以昼[话题]# #夏以昼[话题]# #talkmaker[话题]#</td>\n",
       "      <td>2025-03-01 03:00:11</td>\n",
       "      <td>2025-03-01 03:00:12</td>\n",
       "      <td>66067a58000000000d025499</td>\n",
       "      <td>商秋宴</td>\n",
       "      <td>湖北</td>\n",
       "      <td>恋与深空夏以昼,夏以昼,talkmaker</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:00:01</td>\n",
       "      <td>False</td>\n",
       "      <td>[恋与深空夏以昼, 夏以昼, talkmaker]</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>湖北</td>\n",
       "      <td>Caleb Post</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67c275e8000000002602dfc2</td>\n",
       "      <td>normal</td>\n",
       "      <td>DeepSeek造福人类[色色R]终于说出来了，夏以昼你不是胆小鬼#恋与深空夏以昼[话题]#</td>\n",
       "      <td>DeepSeek造福人类[色色R]终于说出来了，夏以昼你不是胆小鬼#恋与深空夏以昼[话题]#</td>\n",
       "      <td>2025-03-01 02:50:16</td>\n",
       "      <td>2025-03-01 02:58:17</td>\n",
       "      <td>5fb658300000000001005cb4</td>\n",
       "      <td>圈圈</td>\n",
       "      <td>北京</td>\n",
       "      <td>恋与深空夏以昼</td>\n",
       "      <td>...</td>\n",
       "      <td>0 days 00:08:01</td>\n",
       "      <td>False</td>\n",
       "      <td>[恋与深空夏以昼]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>北京</td>\n",
       "      <td>Caleb Post</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    note_id    type  \\\n",
       "0  67c27a66000000000603d771   video   \n",
       "1  67c27a45000000002903da90  normal   \n",
       "2  67c27a2c0000000006028cc9  normal   \n",
       "3  67c2783b000000000602822a  normal   \n",
       "4  67c275e8000000002602dfc2  normal   \n",
       "\n",
       "                                               title  \\\n",
       "0                                            是谁的卡册来了   \n",
       "1  哇塞，这就是你们温良哥推吗，说不过就开始举报了\\n#沈星回[话题]#  #夏以昼的女人是小偷...   \n",
       "2                                       就这么和夏以昼叱咤风云😼   \n",
       "3                                          模仿夏以昼签名被抓   \n",
       "4     DeepSeek造福人类[色色R]终于说出来了，夏以昼你不是胆小鬼#恋与深空夏以昼[话题]#   \n",
       "\n",
       "                                                desc                time  \\\n",
       "0  给大家准备的福福来啦\\n﻿#恋与深空[话题]#﻿ ﻿#拆卡[话题]#﻿ ﻿#二创[话题]#﻿... 2025-03-01 03:09:26   \n",
       "1  哇塞，这就是你们温良哥推吗，说不过就开始举报了\\n#沈星回[话题]#  #夏以昼的女人是小偷... 2025-03-01 03:08:53   \n",
       "2  过了两年，妹也偷偷去参加了比武大会，各家很快就认出来妹用的招式是夏以昼的影子\\n妹和哥一样默... 2025-03-01 03:08:28   \n",
       "3            #恋与深空夏以昼[话题]# #夏以昼[话题]# #talkmaker[话题]# 2025-03-01 03:00:11   \n",
       "4     DeepSeek造福人类[色色R]终于说出来了，夏以昼你不是胆小鬼#恋与深空夏以昼[话题]# 2025-03-01 02:50:16   \n",
       "\n",
       "     last_update_time                   user_id nickname ip_location  \\\n",
       "0 2025-03-01 03:09:27  666c6100000000000d026ec1   芝士塔爱拆卡          河北   \n",
       "1 2025-03-01 03:08:53  60587996000000000101f0c5       沈珏          江苏   \n",
       "2 2025-03-01 03:08:29  632510f2000000002303c666  下一周有下雨天          广西   \n",
       "3 2025-03-01 03:00:12  66067a58000000000d025499      商秋宴          湖北   \n",
       "4 2025-03-01 02:58:17  5fb658300000000001005cb4       圈圈          北京   \n",
       "\n",
       "                               tag_list  ...       time_diff content_edit  \\\n",
       "0        恋与深空,拆卡,二创,沈星回,黎深,祁煜,秦彻,夏以昼,卡册  ... 0 days 00:00:01        False   \n",
       "1  沈星回,夏以昼的女人是小偷,夏以昼的女人不读书,夏以昼的女人吃拼好饭中毒  ... 0 days 00:00:00        False   \n",
       "2                      恋与深空夏以昼,夏以昼,恋与深空  ... 0 days 00:00:01        False   \n",
       "3                 恋与深空夏以昼,夏以昼,talkmaker  ... 0 days 00:00:01        False   \n",
       "4                               恋与深空夏以昼  ... 0 days 00:08:01        False   \n",
       "\n",
       "                                        tags liked_count_parsed  \\\n",
       "0   [恋与深空, 拆卡, 二创, 沈星回, 黎深, 祁煜, 秦彻, 夏以昼, 卡册]                  0   \n",
       "1  [沈星回, 夏以昼的女人是小偷, 夏以昼的女人不读书, 夏以昼的女人吃拼好饭中毒]                  0   \n",
       "2                       [恋与深空夏以昼, 夏以昼, 恋与深空]                  0   \n",
       "3                  [恋与深空夏以昼, 夏以昼, talkmaker]                 12   \n",
       "4                                  [恋与深空夏以昼]                  0   \n",
       "\n",
       "  collected_count_parsed comment_count_parsed  share_count_parsed  \\\n",
       "0                      0                    0                   0   \n",
       "1                      0                    0                   0   \n",
       "2                      0                    0                   0   \n",
       "3                      1                    4                   1   \n",
       "4                      0                    0                   0   \n",
       "\n",
       "  ip_location_grouped     post_type  comment_like_ratio  \n",
       "0                  河北  General Post                 NaN  \n",
       "1                  江苏  General Post                 NaN  \n",
       "2                  广西    Caleb Post                 NaN  \n",
       "3                  湖北    Caleb Post            0.333333  \n",
       "4                  北京    Caleb Post                 NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed2a5854-9f96-4d48-939b-2a6aad431cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/cleaned_raw.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875c66c1-ed1f-4ba3-b413-8b2616630039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
